{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import python_utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总共包括四个卷积层和激活函数ReLU，一个最大池\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(SimpleNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,\n",
    "                               out_channels=12,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=12,\n",
    "                               out_channels=12,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=4)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=12,\n",
    "                               out_channels=48,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=48,\n",
    "                               out_channels=48,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc = nn.Linear(in_features=16 * 16 * 48, out_features=num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.relu1(output)\n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "\n",
    "        output = self.pool(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.relu3(output)\n",
    "\n",
    "        output = self.conv4(output)\n",
    "        output = self.relu4(output)\n",
    "\n",
    "        output = output.view(-1, 16 * 16 * 48)\n",
    "\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置后续需要的参数（部分实际未被使用）\n",
    "class VarsConfig(object):\n",
    "    train_data = \"E3_data/train_img\"\n",
    "    test_data = \"E3_data/val_img\"\n",
    "    pre_data = \"E3_data/test_img\"\n",
    "\n",
    "    epoch = 20\n",
    "    batch_size = 256\n",
    "    img_height = 64\n",
    "    img_weight = 64\n",
    "    seed = 666\n",
    "\n",
    "\n",
    "config = VarsConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置图像变换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # 随机旋转变换\n",
    "    transforms.RandomCrop(64, padding=4),  # 随机裁剪\n",
    "    transforms.ToTensor(),  # 转换为tensor格式\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 标准化\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 转换为tensor格式\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 标准化\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练集和测试集\n",
    "train_data = datasets.ImageFolder(root=config.train_data,\n",
    "                                  transform=train_transform)\n",
    "test_data = datasets.ImageFolder(root=config.test_data,\n",
    "                                 transform=test_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=config.batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=config.batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SimpleNet(\n  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (relu1): ReLU()\n  (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (relu2): ReLU()\n  (pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n  (conv3): Conv2d(12, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (relu3): ReLU()\n  (conv4): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (relu4): ReLU()\n  (fc): Linear(in_features=12288, out_features=12, bias=True)\n)\n"
    }
   ],
   "source": [
    "# 检查GPU是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 因为训练多个模型时可能运行的时候出现了GPU内存不足的提示，可以通过下面更改为强制CPU运行\n",
    "#device = \"cpu\"\n",
    "\n",
    "# 生成模型\n",
    "model = SimpleNet(num_classes=12)\n",
    "model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 定义估计函数\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随着epoch的增大将学习率进行降低以提高准确性\n",
    "def adjust_learning_rate(epoch):\n",
    "    lr = 0.001\n",
    "\n",
    "    if epoch > 30:\n",
    "        lr = lr / 1000000\n",
    "    elif epoch > 25:\n",
    "        lr = lr / 100000\n",
    "    elif epoch > 20:\n",
    "        lr = lr / 10000\n",
    "    elif epoch > 15:\n",
    "        lr = lr / 1000\n",
    "    elif epoch > 10:\n",
    "        lr = lr / 100\n",
    "    elif epoch > 5:\n",
    "        lr = lr / 10\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "\n",
    "# 定义模型保存函数\n",
    "def save_models(epoch):\n",
    "    torch.save(model, \"SimpleNet2_{}.mdl\".format(epoch + 1))\n",
    "    print(\"Chekcpoint saved\")\n",
    "\n",
    "\n",
    "# 定义测试集准确度估计过程\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    test_loss = 0.0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        test_acc += torch.sum(prediction == labels.data)\n",
    "\n",
    "    test_acc = test_acc / len(test_data)\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练过程\n",
    "def train(num_epochs):\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_acc = 0.0\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "            # 预测标签\n",
    "            outputs = model(images)\n",
    "            # 计算损失函数值\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 调整参数\n",
    "            optimizer.step()\n",
    "            # 统计损失\n",
    "            train_loss += loss.item()\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            # 计算训练集正确预测数\n",
    "            train_acc += torch.sum(prediction == labels.data)\n",
    "\n",
    "        # 改变学习率\n",
    "        adjust_learning_rate(epoch)\n",
    "\n",
    "        # 计算准确率和损失\n",
    "        train_acc = train_acc / len(train_data)\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # 估计测试集准确度\n",
    "        test_acc, test_loss = test()\n",
    "\n",
    "        # 将更优的模型保存下来\n",
    "        if test_acc > best_acc:\n",
    "            save_models(epoch)\n",
    "            best_acc = test_acc\n",
    "            best_epoch = epoch + 1\n",
    "\n",
    "        print(\n",
    "            \"Epoch {}, Train Accuracy: {} , TrainLoss: {} , Test Accuracy: {}, TestLoss: {}\".\n",
    "            format(epoch + 1, train_acc, train_loss, test_acc, test_loss))\n",
    "    return best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Chekcpoint saved\nEpoch 1, Train Accuracy: 0.3879384696483612 , TrainLoss: 1.7112586089945214 , Test Accuracy: 0.4795999825000763, TestLoss: 1.5487678428085483\nChekcpoint saved\nEpoch 2, Train Accuracy: 0.5599231123924255 , TrainLoss: 1.2696723323168717 , Test Accuracy: 0.5962399840354919, TestLoss: 1.35338894445069\nChekcpoint saved\nEpoch 3, Train Accuracy: 0.6195384860038757 , TrainLoss: 1.1213406652916136 , Test Accuracy: 0.6222400069236755, TestLoss: 1.226692334729798\nChekcpoint saved\nEpoch 4, Train Accuracy: 0.6698154211044312 , TrainLoss: 0.9828149540217843 , Test Accuracy: 0.6618399620056152, TestLoss: 1.1008190634299297\nChekcpoint saved\nEpoch 5, Train Accuracy: 0.7081230878829956 , TrainLoss: 0.8775976074962165 , Test Accuracy: 0.6939199566841125, TestLoss: 1.0256626143747447\nChekcpoint saved\nEpoch 6, Train Accuracy: 0.741753876209259 , TrainLoss: 0.7827363356830567 , Test Accuracy: 0.6966399550437927, TestLoss: 0.9835474454626745\nChekcpoint saved\nEpoch 7, Train Accuracy: 0.7580461502075195 , TrainLoss: 0.7329278937944277 , Test Accuracy: 0.7326399683952332, TestLoss: 0.8655113066945758\nChekcpoint saved\nEpoch 8, Train Accuracy: 0.7945077419281006 , TrainLoss: 0.6386567043272529 , Test Accuracy: 0.7467199563980103, TestLoss: 0.8574642417382221\nChekcpoint saved\nEpoch 9, Train Accuracy: 0.8006000518798828 , TrainLoss: 0.6260867683202263 , Test Accuracy: 0.747439980506897, TestLoss: 0.8553505108064535\nChekcpoint saved\nEpoch 10, Train Accuracy: 0.801861584186554 , TrainLoss: 0.6185885521135931 , Test Accuracy: 0.7524799704551697, TestLoss: 0.8449957626206535\nEpoch 11, Train Accuracy: 0.805400013923645 , TrainLoss: 0.6099623827718375 , Test Accuracy: 0.7482399940490723, TestLoss: 0.8581504748792065\nChekcpoint saved\nEpoch 12, Train Accuracy: 0.8079538941383362 , TrainLoss: 0.6034625533997543 , Test Accuracy: 0.7584799528121948, TestLoss: 0.8504483772783863\nEpoch 13, Train Accuracy: 0.8115846514701843 , TrainLoss: 0.5906787305835663 , Test Accuracy: 0.7552799582481384, TestLoss: 0.8475706394837828\nEpoch 14, Train Accuracy: 0.811984658241272 , TrainLoss: 0.5900529042238326 , Test Accuracy: 0.7557599544525146, TestLoss: 0.8463049287698707\nEpoch 15, Train Accuracy: 0.8136615753173828 , TrainLoss: 0.5879491187456086 , Test Accuracy: 0.7562400102615356, TestLoss: 0.8439937294745932\nEpoch 16, Train Accuracy: 0.8117538690567017 , TrainLoss: 0.5877196556470525 , Test Accuracy: 0.7562400102615356, TestLoss: 0.8459374716087263\nEpoch 17, Train Accuracy: 0.8130461573600769 , TrainLoss: 0.5867930681217374 , Test Accuracy: 0.758080005645752, TestLoss: 0.8407617521529295\nEpoch 18, Train Accuracy: 0.8127846121788025 , TrainLoss: 0.586660055428978 , Test Accuracy: 0.756879985332489, TestLoss: 0.8447195595624496\nEpoch 19, Train Accuracy: 0.8130307793617249 , TrainLoss: 0.5855430477247463 , Test Accuracy: 0.7570399641990662, TestLoss: 0.8445002314995746\nEpoch 20, Train Accuracy: 0.815015435218811 , TrainLoss: 0.5857904414961658 , Test Accuracy: 0.7572000026702881, TestLoss: 0.8433937612844973\n"
    }
   ],
   "source": [
    "best_epoch = train(config.epoch)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}